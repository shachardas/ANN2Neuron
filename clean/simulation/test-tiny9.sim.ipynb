{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import modules.model2sim as sim\n",
    "\n",
    "import torch\n",
	"import torch.nn as nn\n",
	"import numpy as np\n",
	"\n",
	"class customLoss(nn.Module):\n",
	"    def __init__(self, p=0.5):\n",
	"        super().__init__()\n",
	"        self.p = p\n",
	"        self.cost = nn.CrossEntropyLoss()\n",
	"        self.cost2 = nn.L1Loss()\n",
	"\n",
	"    def forward(self, output, labels, scale_true=100, scale_wrong=-20):\n",
	"        # scale_wrong = max(sum(output[0])/len(output[0]), 2) * scale\n",
	"        # scale_true = scale_wrong * 10\n",
	"        tempLabels = torch.ones_like(output) * scale_wrong\n",
	"        for i in range(labels.size(0)):\n",
	"            j = labels[i]\n",
	"            tempLabels[i,j] = scale_true \n",
	"        output_softmax = nn.LogSoftmax()(output)\n",
	"        return self.p    * self.cost2(output, tempLabels) \\\n",
	"            + (1-self.p) * self.cost(output_softmax,labels)\n",
	"\n",
	"\n",
	"#criterion = nn.CrossEntropyLoss()\n",
	"criterion = customLoss()\n",
	"\n",
	"def Binarize(tensor, include_zero = True, minSig=3):\n",
	"    if include_zero:\n",
	"        P_std = 0.25\n",
	"        up_lim = torch.min(0 + P_std*tensor.std(), torch.ones_like(tensor)*minSig)\n",
	"        down_lim = torch.max(0 - P_std*tensor.std(), -1*torch.ones_like(tensor)*minSig)\n",
	"        up_v = (tensor>up_lim).float()\n",
	"        down_v = (tensor<down_lim).float().mul(-1)\n",
	"        return (up_v + down_v)\n",
	"    else:\n",
	"        return tensor.sign()\n",
	"\n",
	"class BinarizeLinear(nn.Linear):\n",
	"\n",
	"    def __init__(self, *kargs, **kwargs):\n",
	"        super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
	"\n",
	"    def forward(self, input):\n",
	"\n",
	"        if input.size(1) != 784:\n",
	"            input.data=Binarize(input.data)\n",
	"        if not hasattr(self.weight,'org'):\n",
	"            self.weight.org=self.weight.data.clone()\n",
	"        self.weight.data=Binarize(self.weight.org)\n",
	"        out = nn.functional.linear(input, self.weight)\n",
	"        if not self.bias is None:\n",
	"            self.bias.org=self.bias.data.clone()\n",
	"            out += self.bias.view(1, -1).expand_as(out)\n",
	"\n",
	"        return out\n",
	"\n",
	"class Net(nn.Module):\n",
	"    def __init__(self):\n",
	"        super(Net, self).__init__()\n",
	"        self.fc1 = BinarizeLinear(784, 50, bias=False)\n",
	"        self.fc4 = BinarizeLinear(50, 10, bias=False)\n",
	"\n",
	"    def forward(self, x):\n",
	"        x = x.view(-1, 28*28)\n",
	"        x = self.fc1(x)\n",
	"        x = self.fc4(x)\n",
	"        return x\n",
	"\"\"\"\n",
	"    def test(self, x):\n",
	"        x = x.view(-1, 28*28)\n",
	"        x = self.fc1(x)\n",
	"        x = self.fc3(x)\n",
	"        x = self.fc4(x)\n",
	"        return x\"\"\"\n",
	"\n",
	"\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"trained_models/test-tiny9.pt\",map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "res, model_act = sim.testMNIST(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse, sum = sim.testSim(res, model_act,4,1,4)\n",
    "pprint(parse)\n",
    "print(\"sum:\",sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
