{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import modules.model2sim as sim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class customLoss(nn.Module):\n",
    "    def __init__(self, p=0.3):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.cost = nn.CrossEntropyLoss()\n",
    "        self.activation = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, output, labels):\n",
    "        tempOut = torch.clone(output)\n",
    "        \n",
    "        for i in range(labels.size(0)):\n",
    "            tempOut[i,labels[i]] = -1 * tempOut[i,labels[i]]\n",
    "\n",
    "        tempOut = torch.where(tempOut>-1,tempOut+2,torch.zeros_like(tempOut))\n",
    "\n",
    "        return self.p    * torch.mean(tempOut) \\\n",
    "            + (1-self.p) * self.cost(self.activation(output),labels)\n",
    "\n",
    "\n",
    "criterion = customLoss()\n",
    "\n",
    "def Binarize(tensor, include_zero = False, minSig=3):\n",
    "    if include_zero:\n",
    "        P_std = 0.25\n",
    "        up_lim = torch.max(0 + P_std*tensor.std(), torch.ones_like(tensor)*minSig)\n",
    "        down_lim = torch.min(0 - P_std*tensor.std(), -1*torch.ones_like(tensor)*minSig)\n",
    "        up_v = (tensor>up_lim).float()\n",
    "        down_v = (tensor<down_lim).float().mul(-1)\n",
    "        return (up_v + down_v)\n",
    "    else:\n",
    "        return tensor.sign()\n",
    "\n",
    "class BinarizeLinear(nn.Linear):\n",
    "\n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        super(BinarizeLinear, self).__init__(*kargs, **kwargs)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        if input.size(1) != 784:\n",
    "            input.data=Binarize(input.data)\n",
    "        if not hasattr(self.weight,'org'):\n",
    "            self.weight.org=self.weight.data.clone()\n",
    "        self.weight.data=Binarize(self.weight.org)\n",
    "        out = nn.functional.linear(input, self.weight)\n",
    "        if not self.bias is None:\n",
    "            self.bias.org=self.bias.data.clone()\n",
    "            out += self.bias.view(1, -1).expand_as(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# simplified batchnorm with no mean normalization and separate learnable parameters for positive and negatives\n",
    "class SignSensitiveBatchNorm1d(nn.BatchNorm1d):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        super(SignSensitiveBatchNorm1d, self).__init__(size)\n",
    "        self.eps = 1e-5\n",
    "        self.l1 = nn.Parameter(torch.ones(size))\n",
    "        self.l2 = nn.Parameter(torch.ones(size))\n",
    "        self.running_var = torch.ones(size)\n",
    "        self.momentum = 0.1\n",
    "\n",
    "    def forward(self, input):\n",
    "        device = input.get_device()\n",
    "        if input.size()[0] != 1:\n",
    "            self.running_var = (1-self.momentum) * self.running_var + self.momentum * torch.var(input, keepdim=True, dim=0)\n",
    "            bottom = torch.sqrt(torch.var(input, keepdim=True, dim=0) + self.eps)\n",
    "        else:\n",
    "            bottom = torch.sqrt(self.running_var + self.eps)\n",
    "\n",
    "        top = input * torch.sigmoid(10 * input) * self.l1 + input * torch.sigmoid(-10 * input) * self.l2\n",
    "        \n",
    "        out = top/bottom\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, n_iters, withBias = False):\n",
    "        super(BinarizedRNN, self).__init__()\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        \n",
    "        self.InputLinear = BinarizeLinear(inputSize, hiddenSize, bias = withBias)\n",
    "        self.hiddenLinear = BinarizeLinear(hiddenSize, hiddenSize, bias = withBias)\n",
    "        self.outputLinear = BinarizeLinear(hiddenSize, outputSize, bias = withBias)\n",
    "\n",
    "        self.gates = nn.Parameter(torch.ones(n_iters))\n",
    "        self.hiddenLinear.weight = nn.Parameter(torch.eye(hiddenSize))\n",
    "\n",
    "        self.tanh = nn.Hardtanh()\n",
    "        self.hiddenBatchNorm = SignSensitiveBatchNorm1d(hiddenSize)\n",
    "        self.outputBatchNorm = SignSensitiveBatchNorm1d(outputSize)\n",
    "\n",
    "        self.hiddenOutput = torch.zeros(hiddenSize).to(device)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hiddenOutput = torch.zeros(1,self.hiddenSize).to(device)\n",
    "        out = torch.zeros(x.size()[0],x.size()[1],self.outputSize).to(device)\n",
    "        for i, x_i in enumerate(x):\n",
    "            hidden = self.InputLinear(x_i) + self.gates[i]*self.hiddenLinear(self.hiddenOutput)\n",
    "            hidden = self.tanh(hidden)\n",
    "            hidden = self.hiddenBatchNorm(hidden)\n",
    "            self.hiddenOutput = hidden\n",
    "\n",
    "            out_i = self.outputLinear(hidden)\n",
    "            out[i] = out_i\n",
    "        return out\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, inputSize = 2, outputSize = 5, hiddenSize = 50, n_iters = 20):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.BRNN1 = BinarizedRNN(inputSize=inputSize,hiddenSize=hiddenSize,outputSize=outputSize,n_iters=n_iters)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.BRNN1(x)\n",
    "        return x[-1]\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"trained_models/rnn.pt\",map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "print(\"model loaded\")\n",
    "seqs = torch.load('trained_models/rnn.squences')\n",
    "res, model_act = sim.testRNN(model, seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse, sum = sim.testSim(res, model_act,4,1,4)\n",
    "pprint(parse)\n",
    "print(\"sum:\",sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
